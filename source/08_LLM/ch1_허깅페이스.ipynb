{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23cc6cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:90% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
       "div.text_cell_render.rendered_html{font-size:12pt;}\n",
       "div.output {font-size:12pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:12pt;}\n",
       "div.prompt {min-width:70px;}}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
       "table.dataframe{font-size:12px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:90% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
    "div.text_cell_render.rendered_html{font-size:12pt;}\n",
    "div.output {font-size:12pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:12pt;}\n",
    "div.prompt {min-width:70px;}}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
    "table.dataframe{font-size:12px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c350d23",
   "metadata": {},
   "source": [
    "<b><font size=\"6\" color=\"#009e84\"> ch01. 허깅페이스 </font></b>\n",
    "\n",
    "- Inference API 이용 : 모델의 결과를 surver에서\n",
    "- pipeline() 이용 : 모델을 다운로드받아 모델의 결과를 local에서\n",
    "    - raw text → tokenizer → model → [0.11, 0.55, 0.32, ...] logits값으로 알아서 argmax해서 prediction결과 출력\n",
    "    \n",
    "\n",
    "**허깅페이스 transformers에서 지원하는 task**\n",
    "\n",
    "- 'sentiment-analysis' : 'text-classification'의 별칭(감정분석 전용으로 사용)\n",
    "- 'text-classification' : 감정분석, 뉴스분류, 리뷰분류 등 일반적인 문장 분류\n",
    "- 'zero-shot-classification' : 레이블을 학습 없이 주어진 후보군 중에서 분류\n",
    "- 'token-classification' : 개체명 인식(NER : Named Entity Recognition) 등 단위 라벨링\n",
    "- 'ner' : 'token-classification'의 별칭\n",
    "- 'fill-mask' : 빈칸채우기\n",
    "- 'text-generation' : 텍스트 생성(GPT류 모델에 사용)\n",
    "- 'text2text-generation' : 번역, 요약 등 입력 → 출력 변환\n",
    "    - 'translation' : 번역\n",
    "    - 'summarization' : 텍스트 요약\n",
    "    - 'question-answering' : 주어진 context를 보고 질문에 답하기.\n",
    "- 'image-to-text' : 그림을 설명\n",
    "- 'image-classification' : 이미지 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac02d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import logging\n",
    "# 경고 제거\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# transformers 로깅 레벨 조정\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Hugging Face symlink 경고 제거\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# from transformers import pipeline, logging as hf_logging\n",
    "# hf_logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417f824d",
   "metadata": {},
   "source": [
    "# 1. 텍스트 기반 감정분석(긍정/부정)\n",
    "\n",
    "- C:\\Users\\Admin\\.cache\\huggingface 모델 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f96c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "495e0990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241749cc96aa41ae8cf180d9c84a8d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5433bba76d9d4cc6b73d004a58525a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada28408ff9543ea9f41dc397d39f750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735e86b768854e69a0c7432dccb0cefe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task='sentiment-analysis')\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab3264f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9995144605636597}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task='text-classification',\n",
    "                      model='distilbert/distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "# 감정분석시 내용이 많으면 list로 \n",
    "classifier([\"I've been waiting for a HuggingFace course my whole life.\",\n",
    "            \"I hate this so much\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72e060fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.857815682888031},\n",
       " {'label': 'POSITIVE', 'score': 0.9998821020126343}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"이 영화 정말 최고였어요. 감동적이고 연기가 대단해\", # 한글은 학습하지 않아서 랜덤\n",
    "            \"This movie was the best. It's touching, and the acting is amazing\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6be6692c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8577604293823242}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('이 물건 정말 사고 싶어요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54c69c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998695850372314},\n",
       " {'label': 'NEGATIVE', 'score': 0.9991129040718079},\n",
       " {'label': 'POSITIVE', 'score': 0.700200080871582}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(['I like you', 'I hate you', '나 정말 힘들어요']) # 이렇게 한글은 못알아맞춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb28e0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(task='sentiment-analysis',\n",
    "                      model='matthewburke/korean_sentiment')\n",
    "texts = ['나는 너가 좋아', '당신이 싫어요', '힘들어요', '오늘 기분 최고야']\n",
    "result = classifier(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d8bdef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 너가 좋아 → 긍정 : 0.9558\n",
      "당신이 싫어요 → 부정 : 0.9093\n",
      "힘들어요 → 부정 : 0.9140\n",
      "오늘 기분 최고야 → 긍정 : 0.9720\n"
     ]
    }
   ],
   "source": [
    "for text, result in zip(texts, classifier(texts)):\n",
    "    label = '긍정' if result['label']=='LABEL_1' else '부정'\n",
    "    print(f\"{text} → {label} : {result['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffc81d6",
   "metadata": {},
   "source": [
    "# 2. 제로샷분류(Zero-shot 분류)\n",
    "\n",
    "- 기계학습 및 자연어처리에서 각 개별 작업에 대한 특정 교육없이 작업을 수행할 수 있는 모형(비지도학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e35e4673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7318bbe1c8742ae8b1104884eda62ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3956f5e4a6b642fc9d3e5af07158a86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72626b5e74854e738287bfe73c648995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63bb51bccdaa4864ab8ec82e861baedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80c78230703490882095d94083df356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672ce77e14234df8b7813317a3d2bce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I have a problem with my iphone that needs to be resolved asap!',\n",
       " 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'],\n",
       " 'scores': [0.5227580070495605,\n",
       "  0.45814019441604614,\n",
       "  0.0142647260800004,\n",
       "  0.0026850001886487007,\n",
       "  0.002152054337784648]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 제로샷은 매개변수가 2개 들어가야함\n",
    "classifier = pipeline(task='zero-shot-classification')\n",
    "classifier(\"I have a problem with my iphone that needs to be resolved asap!\", # 내용\n",
    "           candidate_labels=['urgent', 'not urgent', 'phone', 'tablet','computer']) # 타겟변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96aa02ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'One day I well see the world',\n",
       " 'labels': ['travel', 'cooking', 'dancing'],\n",
       " 'scores': [0.9938077926635742, 0.003099897177889943, 0.003092351369559765]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_classify = \"One day I well see the world\"\n",
    "candidate_labels = ['travel', 'cooking','dancing']\n",
    "classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bbb5e3",
   "metadata": {},
   "source": [
    "# 3. text 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b8582ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'in this course. We will teach you how to build your own tools to solve your own problems. We will teach you how to create code that works for you. We will teach you how to use a project manager to manage your project with ease. We will teach you how to build new tools to solve problems for you. We will teach you how to use a project manager to manage your project with ease. We will teach you how to use a project manager to manage your project with ease. We will teach you how to use a project manager to manage your project with ease.\\n\\n\\nWe will teach you how to build your own tools to solve your own problems. We will teach you how to use a project manager to manage your project with ease. We will teach you how to use a project manager to manage your project with ease. We will teach you how to build your own tools to solve your own problems. We will teach you how to use a project manager to manage your project with ease. We will teach you how to use a project manager to manage your project with ease. We will teach you how to build your own tools to solve your own problems. We will teach you how to build your own tools to solve your own problems. We will teach you how to build your own tools to solve your own problems.'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "# set_seed(2) 시드값 맞추는것. 실행할때마다 결과가 달라지는게 싫을경우\n",
    "\n",
    "generation = pipeline(task='text-generation', model='openai-community/gpt2') # 텍스트 생성. gpt3부터는 허깅페이스 없음\n",
    "generation('in this course. We will teach you how to',\n",
    "           pad_token_id = generation.tokenizer.eos_token_id) \n",
    "# pad_token_id 경고를 없애려고 setting. 안써도 상관없음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3588694f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this course. We will teach you how to create virtual objects, how to use virtual controllers to implement your application, and how to create classes, functions, and properties. We will cover the basics of creating virtual objects, how to create virtual controllers, and how to use virtual services. We'll discuss the fundamentals of virtual objects and how to use services to create virtual objects. We'll also cover the various ways to use virtual services to create virtual objects and how to use virtual services. We'll discuss the concepts of virtual methods, virtual objects, and virtual virtual functions. We'll also learn how to use virtual functions to create virtual functions and how to use virtual services. We'll also learn how to use virtual functions with virtual objects. And we'll get you started on this course!\n",
      "\n",
      "Virtual Objects\n",
      "\n",
      "In this course, we'll learn how to create virtual objects, how to use virtual controllers, how to use virtual services, and how to use virtual services. We will cover the basics of creating virtual objects, how to use virtual controllers, how to use virtual services, and how to use virtual services. We'll also cover the various ways to use virtual services with virtual objects. And we'll get you started on this course!\n",
      "\n",
      "Virtual Functions\n",
      "\n",
      "In this course, we'll learn how to create\n"
     ]
    }
   ],
   "source": [
    "result = generation('in this course. We will teach you how to',\n",
    "                    pad_token_id = generation.tokenizer.eos_token_id) \n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b57cd6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 과정은 다음과 같은 방법을 알려드려요. 때려을 것한 과정은 다음과 같은 다음과 다음과 다음과 알려드려과 같은 다음과 알려드려과 같은 다음과 알려드려과 같은 다음과 같은 다음과 알려드려과 같은 다음과 알려드려과 같은 다음과 알려드려과 같은 다음과 알려�\n"
     ]
    }
   ],
   "source": [
    "generation = pipeline(task='text-generation', model='openai-community/gpt2') \n",
    "result = generation('이 과정은 다음과 같은 방법을 알려드려요.',\n",
    "                    pad_token_id = generation.tokenizer.eos_token_id)\n",
    "print(result[0]['generated_text']) # 한글을 인식까지만 하고 그 뒤로는 말이 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcad0f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 과정은 다음과 같은 방법을 알려드려요. 먼저, 그 아이가 원하는 것 중에서 내가 희망하는 것을 선택할 수 있도록 해주세요. 그리고 그에 따라 그에 따른 나의 목표에 도달하는 법을 적어주세요\"라고 말한다.\n",
      "이것을 이 책의 소개에서는 ‘맞춤형’, ‘스몰티켓’, ‘그것이 나를 선택한 이유인가에 대한 답’ 등의 다양한 형태로 설명한다.\n",
      "이 책은 이런 유형의 학습법에 익숙하지 않은 많은 학부모를 상대로 한 것으로, 자신의 수준에 맞는 학습을 효과적으로 제시할 수 있다는 점에서 교육 현장에서도 인기 높다.\n",
      "실제로 2009년 12월 출간된 이 책\n"
     ]
    }
   ],
   "source": [
    "generation = pipeline(task='text-generation', model='skt/kogpt2-base-v2') \n",
    "result = generation('이 과정은 다음과 같은 방법을 알려드려요.',\n",
    "                    pad_token_id = generation.tokenizer.eos_token_id,\n",
    "                    max_new_tokens = 100,     # 생성할 최대 길이(생성할 토큰 수)\n",
    "                    num_return_sequences = 1, # 생성할 문장 갯수\n",
    "                    do_sample = True,         # 다양한 샘플 사용\n",
    "                    top_k = 50,               # top-k 샘플링 (확률 높은 상위 50개 토큰만 사용)\n",
    "                    top_p = 0.95,             # 확률이 높은 순서대로 95%가 될 때까지의 단어들로만 후보로 사용\n",
    "                    temperature=1.2,          # 창의성 조절(낮을수록 보수적. 높을수록 창의적)\n",
    "                    no_repeat_ngram_size=2)   # 반복 방지\n",
    "                    \n",
    "print(result[0]['generated_text']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273752bd",
   "metadata": {},
   "source": [
    "# 4. 마스크(빈칸) 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d141207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.19275707006454468,\n",
       "  'token': 3299,\n",
       "  'token_str': ' doctor',\n",
       "  'sequence': \"I'm going to hospital and meet a doctor\"},\n",
       " {'score': 0.06794589757919312,\n",
       "  'token': 27321,\n",
       "  'token_str': ' psychiatrist',\n",
       "  'sequence': \"I'm going to hospital and meet a psychiatrist\"}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(task='fill-mask', model='distilbert/distilroberta-base') # 마스크 채우기\n",
    "unmasker(\"I'm going to hospital and meet a <mask>\",\n",
    "         top_k=2) # top_k 기본값은 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec794e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unmasker('병원에 가서 <mask>를 만날거에요') 기본언어 영어라 안나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed21c00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.0629730075597763,\n",
       "  'token': 265,\n",
       "  'token_str': ' business',\n",
       "  'sequence': \"Hello, I'm a business model.\"},\n",
       " {'score': 0.038101598620414734,\n",
       "  'token': 18150,\n",
       "  'token_str': ' freelance',\n",
       "  'sequence': \"Hello, I'm a freelance model.\"},\n",
       " {'score': 0.03764132782816887,\n",
       "  'token': 774,\n",
       "  'token_str': ' role',\n",
       "  'sequence': \"Hello, I'm a role model.\"},\n",
       " {'score': 0.037326786667108536,\n",
       "  'token': 2734,\n",
       "  'token_str': ' fashion',\n",
       "  'sequence': \"Hello, I'm a fashion model.\"},\n",
       " {'score': 0.026023676618933678,\n",
       "  'token': 24526,\n",
       "  'token_str': ' Playboy',\n",
       "  'sequence': \"Hello, I'm a Playboy model.\"}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Hello, I'm a <mask> model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e0a6552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8bc1ac8fd84c7eab426fb30efce8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7b4e01068748d08fa3890cd9392b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8520fb7ac78446a9f0caa61b39f3828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a31436d5f244a69b4c348c9dc005b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb243fe5a8c4bbf870c85a19ba3a08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1441437155008316,\n",
       "  'token': 2535,\n",
       "  'token_str': 'role',\n",
       "  'sequence': \"hello, i ' m a role model.\"},\n",
       " {'score': 0.14175789058208466,\n",
       "  'token': 4827,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': \"hello, i ' m a fashion model.\"}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(task='fill-mask', model='google-bert/bert-base-uncased') # 마스크 채우기\n",
    "unmasker(\"Hello, I'm a [MASK] model.\",\n",
    "         top_k=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58528c18",
   "metadata": {},
   "source": [
    "## ※ InferenceAPI 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40ab50ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "# os.environ['HF_TOKEN']\n",
    "# 허깅페이스 토큰을 READ권한으로 생성하여 .env에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3cc448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c55f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963b74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2707d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c8325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7b33d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c074e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d37c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfbc6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp (ipykernel)",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
