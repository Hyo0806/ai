{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "850f7ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:90% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
       "div.text_cell_render.rendered_html{font-size:12pt;}\n",
       "div.output {font-size:12pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:12pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
       "table.dataframe{font-size:12px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:90% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
    "div.text_cell_render.rendered_html{font-size:12pt;}\n",
    "div.output {font-size:12pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:12pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
    "table.dataframe{font-size:12px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b36f0ab",
   "metadata": {},
   "source": [
    "<b><font size=\"6\" color=\"red\">ch14. ì›¹ë°ì´í„° ìˆ˜ì§‘ - ë™ì </font></b>\n",
    "\n",
    "# 1ì ˆ. Seleniumì„ ì´ìš©í•œ ë™ì  ì›¹í¬ë¡¤ë§ ë¬¸ë²•\n",
    "\n",
    "- Selenium docs : https://selenium-python.readthedocs.io/\n",
    "`pip install selenium`\n",
    "\n",
    "- importì—ì„œ ì—ëŸ¬ë‚  ê²½ìš°\n",
    "`pip install requests`ë‚˜ `conda install urllib3==1.26.18`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae56f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9476c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://www.python.org\")\n",
    "elem = driver.find_element(By.NAME, 'q')\n",
    "elem.clear()\n",
    "elem.send_keys('pycon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e316307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "elem.send_keys(Keys.RETURN) # Enterë¥¼ ì…ë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3111c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_elem = driver.find_element(By.CSS_SELECTOR, 'button#submit')\n",
    "btn_elem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2782725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = driver.find_elements(By.CSS_SELECTOR, 'li > h3 > a')\n",
    "for result in result_list:\n",
    "    title = result.text\n",
    "    link  = result.get_attribute('href')\n",
    "    print('{} - {}'.format(title, link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38ad6a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSF PyCon Trademark Usage Policy - /psf/trademarks/pycon\n",
      "PyCon Italia 2016 (PyCon Sette) - /events/python-events/378/\n",
      "PyCon Australia 2013 - /events/python-events/57/\n",
      "PyCon AU 2019 - /events/python-events/776/\n",
      "PyCon NL 2025 - /events/python-events/2084/\n",
      "PyCon Australia 2014 - /events/python-events/10/\n",
      "PyCon Ireland 2012 - /events/python-events/76/\n",
      "PyCon Ireland 2016 - /events/python-events/429/\n",
      "PyCon Ireland 2022 - /events/python-events/1320/\n",
      "PyCon Australia 2014 - /events/python-events/1447/\n",
      "PyCon Ireland 2024 - /events/python-events/1862/\n",
      "PyCon APAC 2025 - /events/python-events/1879/\n",
      "PyCon AU 2018 - /events/python-events/696/\n",
      "PyCon APAC 2022 - /events/python-events/1216/\n",
      "PyCon PH 2024 - /events/python-events/1661/\n",
      "PyCon Ireland 2023 - /events/python-events/1568/\n",
      "PyCon PL 2014 - /events/python-events/191/\n",
      "PyCon MY 2015 - /events/python-events/313/\n",
      "PyCon Ireland 2015 - /events/python-events/333/\n",
      "PyCon AU 2015 - /events/python-events/273/\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "result_list = soup.select('li > h3 > a')\n",
    "for result in result_list:\n",
    "    print(\"{} - {}\".format(result.text, result.attrs['href']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a8c8de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.python.org/search/?q=pycon&submit=\n",
      "ParseResult(scheme='https', netloc='www.python.org', path='/search/', params='', query='q=pycon&submit=', fragment='')\n",
      "https://www.python.org\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "current_url =driver.current_url # ì…€ë ˆë‹ˆìœ°ì„ í†µí•´ ì ‘ê·¼í•œ url\n",
    "print(current_url)\n",
    "parse_url = urlparse(current_url)\n",
    "print(parse_url)\n",
    "domain = f'{parse_url.scheme}://{parse_url.netloc}'\n",
    "print(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e628f2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSF PyCon Trademark Usage Policy - https://www.python.org/psf/trademarks/pycon\n",
      "PyCon Italia 2016 (PyCon Sette) - https://www.python.org/events/python-events/378/\n",
      "PyCon Australia 2013 - https://www.python.org/events/python-events/57/\n",
      "PyCon AU 2019 - https://www.python.org/events/python-events/776/\n",
      "PyCon NL 2025 - https://www.python.org/events/python-events/2084/\n",
      "PyCon Australia 2014 - https://www.python.org/events/python-events/10/\n",
      "PyCon Ireland 2012 - https://www.python.org/events/python-events/76/\n",
      "PyCon Ireland 2016 - https://www.python.org/events/python-events/429/\n",
      "PyCon Ireland 2022 - https://www.python.org/events/python-events/1320/\n",
      "PyCon Australia 2014 - https://www.python.org/events/python-events/1447/\n",
      "PyCon Ireland 2024 - https://www.python.org/events/python-events/1862/\n",
      "PyCon APAC 2025 - https://www.python.org/events/python-events/1879/\n",
      "PyCon AU 2018 - https://www.python.org/events/python-events/696/\n",
      "PyCon APAC 2022 - https://www.python.org/events/python-events/1216/\n",
      "PyCon PH 2024 - https://www.python.org/events/python-events/1661/\n",
      "PyCon Ireland 2023 - https://www.python.org/events/python-events/1568/\n",
      "PyCon PL 2014 - https://www.python.org/events/python-events/191/\n",
      "PyCon MY 2015 - https://www.python.org/events/python-events/313/\n",
      "PyCon Ireland 2015 - https://www.python.org/events/python-events/333/\n",
      "PyCon AU 2015 - https://www.python.org/events/python-events/273/\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "result_list = soup.select('li > h3 > a')\n",
    "for result in result_list:\n",
    "    print(\"{} - {}\".format(result.text, domain+result.attrs['href']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48a135c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close() # ë¸Œë¼ìš°ì € ì¢…ë£Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3a1dbc",
   "metadata": {},
   "source": [
    "# 2ì ˆ. ë™ì ì›¹í¬ë¡¤ë§ ì˜ˆì œ\n",
    "## 2.1 ë‹¤ìŒë‰´ìŠ¤ê²€ìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1a47603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²€ìƒ‰í•  ë‹¨ì–´ëŠ”?ë¹„íŠ¸ì½”ì¸\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.daum.net/')\n",
    "# driver.implicitly_wait(0.5) # ìµœëŒ€ë¡œ 0.5ì´ˆë™ì•ˆ ëŒ€ê¸°\n",
    "time.sleep(0.5) # 0.5ì´ˆ ë©ˆì¶¤\n",
    "driver.find_element(By.CLASS_NAME, 'tf_keyword').click()\n",
    "query = input('ê²€ìƒ‰í•  ë‹¨ì–´ëŠ”?')\n",
    "driver.find_element(By.CSS_SELECTOR, 'input[type=\"text\"]').send_keys(query)\n",
    "driver.find_element(By.CLASS_NAME, 'btn_ksearch').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a42910f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‰´ìŠ¤ íƒ­ í´ë¦­\n",
    "\n",
    "# driver.find_elements(By.CSS_SELECTOR, 'ul.list_tab > li')[1].click() ì´ê±´ ì²­ë°”ì§€ì¼ ê²½ìš°ì—ëŠ” 1ë²ˆì§¸ê°€ ì‡¼í•‘ì´ë¼ì„œ ì•„ë˜ì²˜ëŸ¼ í•˜ëŠ”ê²ƒ\n",
    "driver.find_element(By.LINK_TEXT, 'ë‰´ìŠ¤').click() #'a'ë§í¬ê°€ ê±¸ë ¤ìˆìœ¼ë©´ì„œ ì •í™•í•˜ê²Œ 'ë‰´ìŠ¤'í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ê²ƒ í•˜ë‚˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f85516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‰´ìŠ¤ ì œëª©ê³¼ linkë¥¼ list ì¶”ê°€\n",
    "\n",
    "news_list = []\n",
    "strongs = driver.find_elements(By.CSS_SELECTOR, 'div.item-title > strong')\n",
    "#print(len(strongs))\n",
    "for strong in strongs:\n",
    "    a = strong.find_element(By.TAG_NAME, 'a')\n",
    "    title = a.text\n",
    "    link = a.get_attribute('href')\n",
    "    news_list.append([title, link])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be243f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5\n"
     ]
    }
   ],
   "source": [
    "# ë‹¤ìŒ í˜ì´ì§€ë¡œ ë„˜ì–´ê°€ëŠ”ê²ƒ\n",
    "\n",
    "page_nav = driver.find_element(By.CSS_SELECTOR, 'div.inner_paging')\n",
    "print(page_nav.text)\n",
    "next_page = page_nav.find_element(By.LINK_TEXT, '2')\n",
    "next_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6c95c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809be121",
   "metadata": {},
   "source": [
    "## 2.2 í˜ì´ì§• ì²˜ë¦¬\n",
    "\n",
    "- ë‹¤ìŒ ë‰´ìŠ¤ í˜ì´ì§• ì²˜ë¦¬ : ì›í•˜ëŠ” keywordë¥¼ ì›í•˜ëŠ” í˜ì´ì§€ë§Œí¼ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fce5cf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²€ìƒ‰í•  ë‹¨ì–´ëŠ”?ë¹„íŠ¸ì½”ì¸\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ê°€ìƒìì‚° ì¼ì œíˆ ê¸‰ë½â€¦ ë¹„íŠ¸ì½”ì¸ 10ë§Œë‹¬ëŸ¬ ìœ„íƒœ</td>\n",
       "      <td>http://v.daum.net/v/20251112080939100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì¤‘êµ­ 'ê°€ìƒí™”í ì—¬ì™•' í„¸ì ë¹„íŠ¸ì½”ì¸ 9ì¡° 'ì™€ë¥´ë¥´'...ë„ë§ê°„ ì˜êµ­ì„œ ì‹¤í˜•</td>\n",
       "      <td>http://v.daum.net/v/20251112100711544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ETë‹¨ìƒ] ë’·ì „ ëœ ëŒ€êµ­ë¯¼ íˆ¬ìê¸°íšŒâ€¦5ë…„ ëŠ¦ì€ ë¹„íŠ¸ì½”ì¸ í˜„ë¬¼ ETF</td>\n",
       "      <td>http://v.daum.net/v/20251112160328227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"ì—°ë§ì—ëŠ” ì˜¤ë¥¼ê¹Œ\"â€¦ë¹„íŠ¸ì½”ì¸, ETF ìê¸ˆ ìœ ì… ì €ì¡°ì— 1ì–µ5400ë§Œì›ëŒ€ í›„í‡´</td>\n",
       "      <td>http://v.daum.net/v/20251112095516978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>â€˜9ì¡° ë¹„íŠ¸ì½”ì¸ ì—¬ì™•â€™ ëŸ°ë˜ ì§‘ ì¹¨ëŒ€ì„œ ì²´í¬ëœ ìˆœê°„â€¦ì§•ì—­ 11ë…„8ê°œì›” [ì§€ê¸ˆë‰´ìŠ¤]</td>\n",
       "      <td>http://v.daum.net/v/20251112160748420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0                     ê°€ìƒìì‚° ì¼ì œíˆ ê¸‰ë½â€¦ ë¹„íŠ¸ì½”ì¸ 10ë§Œë‹¬ëŸ¬ ìœ„íƒœ   \n",
       "1     ì¤‘êµ­ 'ê°€ìƒí™”í ì—¬ì™•' í„¸ì ë¹„íŠ¸ì½”ì¸ 9ì¡° 'ì™€ë¥´ë¥´'...ë„ë§ê°„ ì˜êµ­ì„œ ì‹¤í˜•   \n",
       "2         [ETë‹¨ìƒ] ë’·ì „ ëœ ëŒ€êµ­ë¯¼ íˆ¬ìê¸°íšŒâ€¦5ë…„ ëŠ¦ì€ ë¹„íŠ¸ì½”ì¸ í˜„ë¬¼ ETF   \n",
       "3    \"ì—°ë§ì—ëŠ” ì˜¤ë¥¼ê¹Œ\"â€¦ë¹„íŠ¸ì½”ì¸, ETF ìê¸ˆ ìœ ì… ì €ì¡°ì— 1ì–µ5400ë§Œì›ëŒ€ í›„í‡´   \n",
       "4  â€˜9ì¡° ë¹„íŠ¸ì½”ì¸ ì—¬ì™•â€™ ëŸ°ë˜ ì§‘ ì¹¨ëŒ€ì„œ ì²´í¬ëœ ìˆœê°„â€¦ì§•ì—­ 11ë…„8ê°œì›” [ì§€ê¸ˆë‰´ìŠ¤]   \n",
       "\n",
       "                                    link  \n",
       "0  http://v.daum.net/v/20251112080939100  \n",
       "1  http://v.daum.net/v/20251112100711544  \n",
       "2  http://v.daum.net/v/20251112160328227  \n",
       "3  http://v.daum.net/v/20251112095516978  \n",
       "4  http://v.daum.net/v/20251112160748420  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.daum.net/')\n",
    "time.sleep(0.5) # 0.5ì´ˆ ë©ˆì¶¤\n",
    "\n",
    "driver.find_element(By.CLASS_NAME, 'tf_keyword').click()\n",
    "query = input('ê²€ìƒ‰í•  ë‹¨ì–´ëŠ”?')\n",
    "driver.find_element(By.CSS_SELECTOR, 'input[type=\"text\"]').send_keys(query)\n",
    "driver.find_element(By.CLASS_NAME, 'btn_ksearch').click()\n",
    "time.sleep(2) \n",
    "\n",
    "# ë‰´ìŠ¤íƒ­ ì´ë™\n",
    "driver.find_element(By.LINK_TEXT, 'ë‰´ìŠ¤').click() \n",
    "\n",
    "# ë‰´ìŠ¤ ì œëª©ê³¼ linkë¥¼ list ì¶”ê°€\n",
    "news_list = []\n",
    "pages = 3 #int(input('ëª‡ í˜ì´ì§€ í¬ë¡¤ë§í• ê¹Œ?'))\n",
    "for page in range(1, pages+1):\n",
    "    strongs = driver.find_elements(By.CSS_SELECTOR, 'div.item-title > strong')\n",
    "    for strong in strongs:\n",
    "        a = strong.find_element(By.TAG_NAME, 'a')\n",
    "        title = a.text\n",
    "        link = a.get_attribute('href')\n",
    "        news_list.append([title, link])\n",
    "    page_nav = driver.find_element(By.CSS_SELECTOR, 'div.inner_paging')\n",
    "    next_page = page_nav.find_element(By.LINK_TEXT, str(page+1))\n",
    "    next_page.click()\n",
    "    time.sleep(2)\n",
    "driver.close()\n",
    "pd.DataFrame(news_list, columns=['title', 'link']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a6d27",
   "metadata": {},
   "source": [
    "## 2.3 ë§ì¶¤ë²• ê²€ì‚¬ê¸°\n",
    "\n",
    "- ë„¤ì´ë²„ ë§ì¶¤ë²• ê²€ì‚¬ê¸° ì´ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6f29d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a265f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”. ë°˜ê°‘ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('http://www.naver.com/')\n",
    "time.sleep(1)\n",
    "\n",
    "elem = driver.find_element(By.ID, 'query')\n",
    "elem.send_keys('ë§ì¶¤ë²• ê²€ì‚¬ê¸°')\n",
    "elem.send_keys(Keys.RETURN) # formíƒœê·¸ì˜ submití´ë¦­ íš¨ê³¼\n",
    "\n",
    "textarea = driver.find_element(By.CLASS_NAME, 'txt_gray')\n",
    "textarea.clear()\n",
    "textarea.send_keys('ì•ˆë‡½í•˜ì„¸ìš”. ë°˜ê°‘ìˆ©ë‹ˆë‹¤. ê°ìƒ¤í•©ë‹ˆë‹¤.')\n",
    "btn = driver.find_element(By.CLASS_NAME, 'btn_check')\n",
    "btn.click()\n",
    "time.sleep(2)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "result = soup.select_one('p._result_text.stand_txt').text\n",
    "print(result)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea76ba3b",
   "metadata": {},
   "source": [
    "### ë§ì¶¤ë²• ê²€ì‚¬ ê¸€ììˆ˜\n",
    "\n",
    "- ë§ì¶¤ë²•ê²€ì‚¬ì „.txtë¥¼ ì½ì–´ 300ì ë‹¨ìœ„ë¡œ ìë¥¸ë‹¤ \n",
    "- listì— ë„£ì–´ ë™ì ì›¹í¬ë¡¤ë§ì„ í•œë‹¤\n",
    "- ê²°ê³¼ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de5d4ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[242, 264, 157]\n",
      "242\n",
      "264\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "with open('data/ch14_ë§ì¶¤ë²•ê²€ì‚¬ì „.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "ready_text = [] # 300ìì”© ë‚˜ëˆ ì§„ text\n",
    "while(len(text)>300):\n",
    "    temp = text[:300]\n",
    "    last_dot_index = temp.rfind('.') #ë’¤ì—ì„œë¶€í„° ì°¾ëŠ” .ì˜ ìœ„ì¹˜\n",
    "    ready_text.append(text[:last_dot_index+1])\n",
    "    text = text[last_dot_index+1:]\n",
    "ready_text.append(text)\n",
    "#print(ready_text)\n",
    "print([len(ready) for ready in ready_text])\n",
    "for ready in ready_text:\n",
    "    print(len(ready))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "131dc316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63a93b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²€ì‚¬ì¤‘.....1/3\n",
      "ê²€ì‚¬ì¤‘.....2/3\n",
      "ê²€ì‚¬ì¤‘.....3/3\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "\n",
    "driver.get('http://www.naver.com/')\n",
    "time.sleep(0.5)\n",
    "\n",
    "elem = driver.find_element(By.ID, 'query')\n",
    "elem.send_keys('ë§ì¶¤ë²• ê²€ì‚¬ê¸°')\n",
    "elem.send_keys(Keys.RETURN) # formíƒœê·¸ì˜ submití´ë¦­ íš¨ê³¼\n",
    "time.sleep(1)\n",
    "\n",
    "textarea = driver.find_element(By.CLASS_NAME, 'txt_gray')\n",
    "results = '' # ë§ì¶¤ë²• ê²€ì‚¬ ì™„ë£Œëœ text\n",
    "for i, ready in enumerate(ready_text):\n",
    "    print(f'ê²€ì‚¬ì¤‘.....{i+1}/{len(ready_text)}')\n",
    "    # textarea.clear()\n",
    "    textarea.send_keys(Keys.CONTROL,'a') # ctrl+a ì´ê±´ ì¶”ì²œì•ˆí•¨ ìœ„ì—ê²ƒ ì¶”ì²œ\n",
    "    textarea.send_keys(ready)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    btn = driver.find_element(By.CLASS_NAME, 'btn_check')\n",
    "    btn.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    result = soup.select_one('p._result_text.stand_txt').text\n",
    "    if 'ê²€ì‚¬ê°€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤' in result:\n",
    "        result += ready+'\\n'\n",
    "    else:\n",
    "        results += result + '\\n'\n",
    "    time.sleep(1)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55326b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë§ì¶¤ë²• ê²€ì‚¬ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì¶œë ¥\n",
    "\n",
    "with open('data/ch14_ë§ì¶¤ë²•ê²€ì‚¬í›„.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d923c4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²€ì‚¬ì¤‘ğŸšŒ__________01/24\n",
      "ê²€ì‚¬ì¤‘___ğŸšŒ_______02/24\n",
      "ê²€ì‚¬ì¤‘______ğŸšŒ____03/24\n",
      "ê²€ì‚¬ì¤‘________ğŸšŒ__04/24\n",
      "ê²€ì‚¬ì¤‘__________ğŸšŒ05/24\n",
      "ê²€ì‚¬ì¤‘ğŸšŒ__________06/24\n",
      "ê²€ì‚¬ì¤‘___ğŸšŒ_______07/24\n",
      "ê²€ì‚¬ì¤‘______ğŸšŒ____08/24\n",
      "ê²€ì‚¬ì¤‘________ğŸšŒ__09/24\n",
      "ê²€ì‚¬ì¤‘__________ğŸšŒ10/24\n",
      "ê²€ì‚¬ì¤‘ğŸšŒ__________11/24\n",
      "ê²€ì‚¬ì¤‘___ğŸšŒ_______12/24\n",
      "ê²€ì‚¬ì¤‘______ğŸšŒ____13/24\n",
      "ê²€ì‚¬ì¤‘________ğŸšŒ__14/24\n",
      "ê²€ì‚¬ì¤‘__________ğŸšŒ15/24\n",
      "ê²€ì‚¬ì¤‘ğŸšŒ__________16/24\n",
      "ê²€ì‚¬ì¤‘___ğŸšŒ_______17/24\n",
      "ê²€ì‚¬ì¤‘______ğŸšŒ____18/24\n",
      "ê²€ì‚¬ì¤‘________ğŸšŒ__19/24\n",
      "ê²€ì‚¬ì¤‘__________ğŸšŒ20/24\n",
      "ê²€ì‚¬ì¤‘ğŸšŒ__________21/24\n",
      "ê²€ì‚¬ì¤‘___ğŸšŒ_______22/24\n",
      "ê²€ì‚¬ì¤‘______ğŸšŒ____23/24\n",
      "ê²€ì‚¬ì¤‘________ğŸšŒ__24/24\n",
      "ê²€ì‚¬ì¤‘ğŸšŒ__________1/3\n",
      "ê²€ì‚¬ì¤‘_____ğŸšŒ_____2/3\n",
      "ê²€ì‚¬ì¤‘__________ğŸšŒ3/3\n"
     ]
    }
   ],
   "source": [
    "# quiz\n",
    "#...........import\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#...........ë§ì¶¤ë²•ê²€ì‚¬ íŒŒì¼ ì—´ê¸°\n",
    "with open('data/ch14_ë§ì¶¤ë²•ê²€ì‚¬ì „_ì˜ì–´ë²ˆì—­ì „.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "ready_text = []\n",
    "while(len(text) > 300):\n",
    "    temp = text[:300]\n",
    "    last_dat_index = temp.rfind('.')\n",
    "    ready_text.append(text[:last_dat_index+1])\n",
    "    text = text[last_dat_index+1:]\n",
    "ready_text.append(text)\n",
    "\n",
    "\n",
    "#...........ë§ì¶¤ë²•ê²€ì‚¬ê¸°\n",
    "driver = webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "\n",
    "driver.get('http://www.naver.com/')\n",
    "time.sleep(0.5)\n",
    "\n",
    "elem = driver.find_element(By.ID, 'query')\n",
    "elem.send_keys('ë§ì¶¤ë²• ê²€ì‚¬ê¸°')\n",
    "elem.send_keys(Keys.RETURN) \n",
    "time.sleep(1)\n",
    "\n",
    "textarea = driver.find_element(By.CLASS_NAME, 'txt_gray')\n",
    "results = '' \n",
    "for i, ready in enumerate(ready_text):\n",
    "    if (i+1)%5 == 1:\n",
    "        print(f'ê²€ì‚¬ì¤‘ğŸšŒ__________{i+1:02}/{len(ready_text)}')\n",
    "    elif (i+1)%5 == 2:\n",
    "        print(f'ê²€ì‚¬ì¤‘___ğŸšŒ_______{i+1:02}/{len(ready_text)}')\n",
    "    elif (i+1)%5 == 3:\n",
    "        print(f'ê²€ì‚¬ì¤‘______ğŸšŒ____{i+1:02}/{len(ready_text)}')\n",
    "    elif (i+1)%5 == 4:\n",
    "        print(f'ê²€ì‚¬ì¤‘________ğŸšŒ__{i+1:02}/{len(ready_text)}')\n",
    "    else :\n",
    "        print(f'ê²€ì‚¬ì¤‘__________ğŸšŒ{i+1:02}/{len(ready_text)}')\n",
    "    textarea.clear()\n",
    "    textarea.send_keys(ready)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    btn = driver.find_element(By.CLASS_NAME, 'btn_check')\n",
    "    btn.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    result = soup.select_one('p._result_text.stand_txt').text\n",
    "    if 'ê²€ì‚¬ê°€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤' in result:\n",
    "        result += ready+'\\n'\n",
    "    else:\n",
    "        results += result + '\\n'\n",
    "    time.sleep(1)\n",
    "driver.close()\n",
    "\n",
    "\n",
    "#...........íŒŒì¼ ì¶œë ¥\n",
    "with open('data/ch14_ë§ì¶¤ë²•ê²€ì‚¬í›„_ì˜ì–´ë²ˆì—­ì „.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(results)\n",
    "\n",
    "    \n",
    "#...........íŒŒíŒŒê³  íŒŒì¼ ì—´ê¸°\n",
    "with open('data/ch14_ë§ì¶¤ë²•ê²€ì‚¬í›„_ì˜ì–´ë²ˆì—­ì „.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "ready_text = []\n",
    "while(len(text) > 3000):\n",
    "    temp = text[:3000]\n",
    "    last_dat_index = temp.rfind('.')\n",
    "    ready_text.append(text[:last_dat_index+1])\n",
    "    text = text[last_dat_index+1:]\n",
    "ready_text.append(text)\n",
    "\n",
    "\n",
    "#...........íŒŒíŒŒê³ \n",
    "driver = webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "\n",
    "driver.get('https://papago.naver.com/')\n",
    "time.sleep(0.5)\n",
    "\n",
    "textarea = driver.find_element(By.CLASS_NAME, 'edit_box___1KtZ3')\n",
    "results = ''\n",
    "for i, ready in enumerate(ready_text):\n",
    "    if (i+1)%3 == 1:\n",
    "        print(f'ê²€ì‚¬ì¤‘ğŸšŒ__________{i+1}/{len(ready_text)}')\n",
    "    elif (i+1)%3 == 2:\n",
    "        print(f'ê²€ì‚¬ì¤‘_____ğŸšŒ_____{i+1}/{len(ready_text)}')\n",
    "    else :\n",
    "        print(f'ê²€ì‚¬ì¤‘__________ğŸšŒ{i+1}/{len(ready_text)}') \n",
    "    textarea.clear()\n",
    "    textarea.send_keys(ready)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    btn = driver.find_element(By.CLASS_NAME, 'btn_text___3-laJ')\n",
    "    btn.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # result = driver.find_element(By.CSS_SELECTOR, 'div#txtTarget').text\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    result = soup.select_one('div.edit_box___1KtZ3.active___3VPGL').text\n",
    "    results += result\n",
    "    time.sleep(3)\n",
    "driver.close()\n",
    "\n",
    "\n",
    "#...........íŒŒì¼ ì¶œë ¥\n",
    "with open('data/ch14_ë§ì¶¤ë²•ê²€ì‚¬í›„_ì˜ì–´ë²ˆì—­í›„.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
